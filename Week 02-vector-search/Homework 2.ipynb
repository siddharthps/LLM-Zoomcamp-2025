{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9616c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7712ed88",
   "metadata": {},
   "source": [
    "### Q1. Embedding the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb5a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f30b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0084bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextEmbedding(model_name=model_handle)\n",
    "query = 'I just discovered the course. Can I join now?'\n",
    "embedding_query = list(model.embed(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f230b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal value in the embedding array: -0.11726373885183883\n"
     ]
    }
   ],
   "source": [
    "min_val = np.array(embedding_query[0]).min()\n",
    "\n",
    "print(f\"Minimal value in the embedding array: {min_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b7894",
   "metadata": {},
   "source": [
    "### Q2. Cosine similarity with another vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c99bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'Can I still join the course after the start date?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daed0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_doc = list(model.embed(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15781e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_query = np.array(list(model.embed(query))[0])\n",
    "embedding_doc = np.array(list(model.embed(doc))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d309cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomalizing the vectors \n",
    "embedding_query /= np.linalg.norm(embedding_query)\n",
    "embedding_doc /= np.linalg.norm(embedding_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44327525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cosine Similarity between the embeddings is: 0.9008528895674548\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity = embedding_query.dot(embedding_doc)\n",
    "\n",
    "print(\"The Cosine Similarity between the embeddings is:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01500b9c",
   "metadata": {},
   "source": [
    "### Q3. Ranking by cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50670213",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f4c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.array([list(model.embed(doc[\"text\"]))[0] for doc in documents])\n",
    "V = V / np.linalg.norm(V, axis=1, keepdims=True)  # L2-normalize each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ecd2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarities = V.dot(embedding_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9c981f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document index: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar document index:\", int(np.argmax(cos_similarities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89878aa",
   "metadata": {},
   "source": [
    "### Q4. Ranking by cosine, version two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d7017b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_texts = [doc['question'] + ' ' + doc['text'] for doc in documents]\n",
    "V_full = np.array([list(model.embed(text))[0] for text in full_texts])\n",
    "V_full = V_full / np.linalg.norm(V_full, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52342c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarities = V.dot(embedding_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4e88793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document index: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Most similar document index:\", int(np.argmax(cos_similarities)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a78e4",
   "metadata": {},
   "source": [
    "No , in other cases it could be different because:\n",
    "\n",
    "    Including the question adds more semantic cues and contextual alignment.\n",
    "\n",
    "    If a text is vague but the question clarifies its intent, the model may now recognize a better match.\n",
    "\n",
    "    Conversely, a noisy or unrelated question might lower the similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fbca35",
   "metadata": {},
   "source": [
    "### Q5. Selecting the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39e238d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db0630a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest embedding dimension available: 384\n"
     ]
    }
   ],
   "source": [
    "min_dim = min(model[\"dim\"] for model in models)\n",
    "print(\"Smallest embedding dimension available:\", min_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194364a5",
   "metadata": {},
   "source": [
    "### Q6. Indexing with qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109d5c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cd77c763ad48d6a69b83deeeed7106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ad903f5d69418c9ff3ae0d59606d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34271899046468aba286aaa0b12d9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990db7afb5f542318af6ae34d592cc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b71ad9724224c118cf57582d7d3118b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c64c2834d044dd3869448455f4ca066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siddharth\\Downloads\\LLM Zoomcamp - 2025\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Siddharth\\AppData\\Local\\Temp\\fastembed_cache\\models--Qdrant--bge-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = TextEmbedding(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9996394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa514634",
   "metadata": {},
   "source": [
    "```bash docker run -p 6333:6333 -p 6334:6334 -v \"${PWD}\\qdrant_storage:/qdrant/storage\" qdrant/qdrant```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4559c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c56419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the collection name\n",
    "collection_name = \"zoomcamp-homework2\"\n",
    "# Delete the collection if it already exsists\n",
    "client.delete_collection(collection_name=collection_name)\n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=384,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c5431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "# Prepare data for indexing\n",
    "payloads = []\n",
    "vectors = []\n",
    "ids = []\n",
    "\n",
    "for doc in documents:\n",
    "    # Combine question + text\n",
    "    full_text = doc[\"question\"] + \" \" + doc[\"text\"]\n",
    "\n",
    "    # Embed\n",
    "    embedding = list(model.embed(full_text))[0]\n",
    "\n",
    "    # Save data\n",
    "    vectors.append(embedding)\n",
    "    payloads.append({\n",
    "        \"course\": doc[\"course\"],\n",
    "        \"question\": doc[\"question\"],\n",
    "        \"text\": doc[\"text\"]\n",
    "    })\n",
    "    ids.append(str(uuid4()))  # Unique ID for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3edc53ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=ids[i],\n",
    "            vector=vectors[i],\n",
    "            payload=payloads[i]\n",
    "        )\n",
    "        for i in range(len(vectors))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "597f6647",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I just discovered the course. Can I join now?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c40b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "    # Embed the query\n",
    "    query_vector = list(model.embed(query))[0]\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=limit,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83a1ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest score from search result: 0.8703172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Siddharth\\AppData\\Local\\Temp\\ipykernel_17472\\3366497221.py:5: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    }
   ],
   "source": [
    "results = search(query)\n",
    "top_score = results[0].score\n",
    "print(\"Highest score from search result:\", top_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
